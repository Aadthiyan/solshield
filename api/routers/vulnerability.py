#!/usr/bin/env python3
"""
Vulnerability Detection API Router

This module provides the main API endpoints for smart contract
vulnerability detection and analysis.
"""

import asyncio
import time
import hashlib
from typing import List, Optional, Dict, Any
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends, Request
from fastapi.responses import JSONResponse
import logging

# Add project directories to path
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

from api.models.schemas import (
    ContractSubmissionRequest, ContractSubmissionResponse,
    ReportRetrievalResponse, VulnerabilityReport,
    BatchSubmissionRequest, BatchSubmissionResponse,
    BatchReportResponse, ErrorResponse
)
from api.utils.inference_engine import InferenceEngine, ModelType
from api.middleware.logging import RequestContext, PerformanceMonitor

# Set up logging
logger = logging.getLogger(__name__)

# Initialize router
router = APIRouter(prefix="/api/v1", tags=["vulnerability-detection"])

# Global instances
inference_engine = None
performance_monitor = PerformanceMonitor()
report_cache = {}  # Simple in-memory cache for reports

async def get_inference_engine() -> InferenceEngine:
    """Dependency to get inference engine instance"""
    global inference_engine
    if inference_engine is None:
        inference_engine = InferenceEngine()
        await inference_engine.initialize()
    return inference_engine

@router.post("/analyze", response_model=ContractSubmissionResponse)
async def analyze_contract(
    request: ContractSubmissionRequest,
    background_tasks: BackgroundTasks,
    inference_engine: InferenceEngine = Depends(get_inference_engine),
    fastapi_request: Request = None
):
    """
    Analyze a smart contract for vulnerabilities
    
    This endpoint accepts Solidity contract code and returns a vulnerability report
    with detailed analysis including vulnerability types, severity levels,
    and optimization suggestions.
    """
    request_id = getattr(fastapi_request.state, 'request_id', 'unknown')
    
    with RequestContext(request_id):
        try:
            # Validate request
            if not request.contract_code.strip():
                raise HTTPException(
                    status_code=400,
                    detail="Contract code cannot be empty"
                )
            
            # Generate contract hash for caching
            contract_hash = hashlib.sha256(request.contract_code.encode()).hexdigest()
            
            # Check cache first
            if contract_hash in report_cache:
                logger.info(f"Returning cached report for contract {contract_hash[:8]}")
                cached_report = report_cache[contract_hash]
                return ContractSubmissionResponse(
                    success=True,
                    message="Analysis completed (cached result)",
                    report_id=cached_report.report_id,
                    estimated_processing_time=0.0
                )
            
            # Perform analysis
            start_time = time.time()
            
            # Convert model type
            model_type = ModelType(request.model_type)
            
            # Analyze contract
            report = await inference_engine.analyze_contract(
                contract_code=request.contract_code,
                model_type=model_type,
                contract_name=request.contract_name
            )
            
            processing_time = time.time() - start_time
            
            # Cache the report
            report_cache[contract_hash] = report
            
            # Record performance metrics
            performance_monitor.record_request(processing_time, True)
            
            # Log successful analysis
            logger.info(f"Contract analysis completed in {processing_time:.2f}s")
            
            return ContractSubmissionResponse(
                success=True,
                message="Analysis completed successfully",
                report_id=report.report_id,
                estimated_processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"Error analyzing contract: {e}")
            performance_monitor.record_request(time.time() - start_time, False)
            
            raise HTTPException(
                status_code=500,
                detail=f"Failed to analyze contract: {str(e)}"
            )

@router.get("/report/{report_id}", response_model=ReportRetrievalResponse)
async def get_report(
    report_id: str,
    fastapi_request: Request = None
):
    """
    Retrieve a vulnerability report by ID
    
    Returns the complete vulnerability analysis report including
    vulnerability details, optimization suggestions, and model predictions.
    """
    request_id = getattr(fastapi_request.state, 'request_id', 'unknown')
    
    with RequestContext(request_id):
        try:
            # Search for report in cache
            report = None
            for cached_report in report_cache.values():
                if cached_report.report_id == report_id:
                    report = cached_report
                    break
            
            if report is None:
                raise HTTPException(
                    status_code=404,
                    detail=f"Report with ID {report_id} not found"
                )
            
            logger.info(f"Retrieved report {report_id}")
            
            return ReportRetrievalResponse(
                success=True,
                message="Report retrieved successfully",
                report=report
            )
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Error retrieving report {report_id}: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to retrieve report: {str(e)}"
            )

@router.post("/analyze/batch", response_model=BatchSubmissionResponse)
async def analyze_contracts_batch(
    request: BatchSubmissionRequest,
    background_tasks: BackgroundTasks,
    inference_engine: InferenceEngine = Depends(get_inference_engine),
    fastapi_request: Request = None
):
    """
    Analyze multiple contracts in batch
    
    Processes up to 10 contracts simultaneously and returns
    batch processing information.
    """
    request_id = getattr(fastapi_request.state, 'request_id', 'unknown')
    
    with RequestContext(request_id):
        try:
            # Validate batch size
            if len(request.contracts) > 10:
                raise HTTPException(
                    status_code=400,
                    detail="Maximum 10 contracts allowed per batch"
                )
            
            # Generate batch ID
            batch_id = f"batch_{int(time.time())}_{request_id[:8]}"
            contract_ids = []
            
            # Process contracts
            start_time = time.time()
            tasks = []
            
            for i, contract_request in enumerate(request.contracts):
                # Generate contract ID
                contract_id = f"{batch_id}_contract_{i}"
                contract_ids.append(contract_id)
                
                # Create analysis task
                task = asyncio.create_task(
                    _analyze_single_contract(
                        contract_request,
                        contract_id,
                        inference_engine
                    )
                )
                tasks.append(task)
            
            # Wait for all analyses to complete
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            processing_time = time.time() - start_time
            
            # Record performance metrics
            performance_monitor.record_request(processing_time, True)
            
            logger.info(f"Batch analysis completed: {batch_id}")
            
            return BatchSubmissionResponse(
                success=True,
                message=f"Batch analysis initiated for {len(request.contracts)} contracts",
                batch_id=batch_id,
                contract_ids=contract_ids,
                estimated_processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"Error in batch analysis: {e}")
            performance_monitor.record_request(time.time() - start_time, False)
            
            raise HTTPException(
                status_code=500,
                detail=f"Failed to process batch: {str(e)}"
            )

@router.get("/batch/{batch_id}", response_model=BatchReportResponse)
async def get_batch_reports(
    batch_id: str,
    fastapi_request: Request = None
):
    """
    Retrieve all reports for a batch analysis
    
    Returns all vulnerability reports for the specified batch ID.
    """
    request_id = getattr(fastapi_request.state, 'request_id', 'unknown')
    
    with RequestContext(request_id):
        try:
            # Find reports for this batch
            batch_reports = []
            processing_status = {}
            
            for cached_report in report_cache.values():
                if cached_report.report_id.startswith(batch_id):
                    batch_reports.append(cached_report)
                    processing_status[cached_report.report_id] = "completed"
            
            if not batch_reports:
                raise HTTPException(
                    status_code=404,
                    detail=f"No reports found for batch {batch_id}"
                )
            
            # Calculate total processing time
            total_processing_time = sum(report.processing_time for report in batch_reports)
            
            logger.info(f"Retrieved {len(batch_reports)} reports for batch {batch_id}")
            
            return BatchReportResponse(
                success=True,
                message=f"Retrieved {len(batch_reports)} reports",
                batch_id=batch_id,
                reports=batch_reports,
                processing_status=processing_status,
                total_processing_time=total_processing_time
            )
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Error retrieving batch reports {batch_id}: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to retrieve batch reports: {str(e)}"
            )

async def _analyze_single_contract(
    contract_request: ContractSubmissionRequest,
    contract_id: str,
    inference_engine: InferenceEngine
) -> VulnerabilityReport:
    """Analyze a single contract (helper function for batch processing)"""
    try:
        # Convert model type
        model_type = ModelType(contract_request.model_type)
        
        # Analyze contract
        report = await inference_engine.analyze_contract(
            contract_code=contract_request.contract_code,
            model_type=model_type,
            contract_name=contract_request.contract_name
        )
        
        # Update report ID
        report.report_id = contract_id
        
        # Cache the report
        contract_hash = hashlib.sha256(contract_request.contract_code.encode()).hexdigest()
        report_cache[contract_hash] = report
        
        return report
        
    except Exception as e:
        logger.error(f"Error analyzing contract {contract_id}: {e}")
        raise

@router.delete("/report/{report_id}")
async def delete_report(
    report_id: str,
    fastapi_request: Request = None
):
    """
    Delete a vulnerability report
    
    Removes the specified report from the cache.
    """
    request_id = getattr(fastapi_request.state, 'request_id', 'unknown')
    
    with RequestContext(request_id):
        try:
            # Find and remove report from cache
            removed = False
            for contract_hash, report in list(report_cache.items()):
                if report.report_id == report_id:
                    del report_cache[contract_hash]
                    removed = True
                    break
            
            if not removed:
                raise HTTPException(
                    status_code=404,
                    detail=f"Report with ID {report_id} not found"
                )
            
            logger.info(f"Deleted report {report_id}")
            
            return {"success": True, "message": f"Report {report_id} deleted successfully"}
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Error deleting report {report_id}: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to delete report: {str(e)}"
            )

@router.get("/reports")
async def list_reports(
    limit: int = 10,
    offset: int = 0,
    fastapi_request: Request = None
):
    """
    List available reports
    
    Returns a paginated list of available vulnerability reports.
    """
    request_id = getattr(fastapi_request.state, 'request_id', 'unknown')
    
    with RequestContext(request_id):
        try:
            # Get all reports
            all_reports = list(report_cache.values())
            
            # Apply pagination
            start_idx = offset
            end_idx = offset + limit
            paginated_reports = all_reports[start_idx:end_idx]
            
            # Create summary for each report
            report_summaries = []
            for report in paginated_reports:
                summary = {
                    "report_id": report.report_id,
                    "contract_name": report.contract_name,
                    "is_vulnerable": report.is_vulnerable,
                    "risk_score": report.risk_score,
                    "vulnerability_count": len(report.vulnerabilities),
                    "timestamp": report.timestamp,
                    "processing_time": report.processing_time
                }
                report_summaries.append(summary)
            
            logger.info(f"Listed {len(report_summaries)} reports (limit={limit}, offset={offset})")
            
            return {
                "success": True,
                "reports": report_summaries,
                "total_count": len(all_reports),
                "limit": limit,
                "offset": offset
            }
            
        except Exception as e:
            logger.error(f"Error listing reports: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to list reports: {str(e)}"
            )
